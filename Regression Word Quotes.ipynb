{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg.score :  0.81\n",
      "[[0.61903279 0.38096721]\n",
      " [0.7062817  0.2937183 ]\n",
      " [0.67587227 0.32412773]\n",
      " ...\n",
      " [0.81504502 0.18495498]\n",
      " [0.48774502 0.51225498]\n",
      " [0.76818266 0.23181734]]\n",
      "[79]\n",
      "[[7.20844867e-01 2.79155133e-01]\n",
      " [8.71098965e-01 1.28901035e-01]\n",
      " [2.19823471e-04 9.99780177e-01]]\n",
      "(150, 2)\n",
      "(150,)\n",
      "log_reg.score(X,Y) :  0.7533333333333333\n",
      "[[0.81269997 0.18730003]\n",
      " [0.46469236 0.53530764]\n",
      " [0.65262124 0.34737876]\n",
      " [0.4539276  0.5460724 ]\n",
      " [0.44856069 0.55143931]\n",
      " [0.63773791 0.36226209]\n",
      " [0.79209608 0.20790392]\n",
      " [0.43253654 0.56746346]\n",
      " [0.62258568 0.37741432]\n",
      " [0.78118492 0.21881508]\n",
      " [0.41665231 0.58334769]\n",
      " [0.77368501 0.22631499]\n",
      " [0.60200875 0.39799125]\n",
      " [0.59680451 0.40319549]\n",
      " [0.76209781 0.23790219]\n",
      " [0.3905738  0.6094262 ]\n",
      " [0.58106486 0.41893514]\n",
      " [0.75010896 0.24989104]\n",
      " [0.7460243  0.2539757 ]\n",
      " [0.74189585 0.25810415]\n",
      " [0.55982469 0.44017531]\n",
      " [0.3600967  0.6399033 ]\n",
      " [0.72925063 0.27074937]\n",
      " [0.72495004 0.27504996]\n",
      " [0.53836318 0.46163682]\n",
      " [0.71622285 0.28377715]\n",
      " [0.71179711 0.28820289]\n",
      " [0.52216874 0.47783126]\n",
      " [0.70282367 0.29717633]\n",
      " [0.51134438 0.48865562]\n",
      " [0.69369106 0.30630894]\n",
      " [0.50050936 0.49949064]\n",
      " [0.68440383 0.31559617]\n",
      " [0.48967387 0.51032613]\n",
      " [0.48425912 0.51574088]\n",
      " [0.67019406 0.32980594]\n",
      " [0.66538584 0.33461416]\n",
      " [0.66054303 0.33945697]\n",
      " [0.28021384 0.71978616]\n",
      " [0.45726603 0.54273397]\n",
      " [0.27155469 0.72844531]\n",
      " [0.4465298  0.5534702 ]\n",
      " [0.63583811 0.36416189]\n",
      " [0.43584322 0.56415678]\n",
      " [0.62574314 0.37425686]\n",
      " [0.25065564 0.74934436]\n",
      " [0.61553753 0.38446247]\n",
      " [0.6103957  0.3896043 ]\n",
      " [0.40940654 0.59059346]\n",
      " [0.40417642 0.59582358]\n",
      " [0.59482642 0.40517358]\n",
      " [0.22702928 0.77297072]\n",
      " [0.38862042 0.61137958]\n",
      " [0.21951242 0.78048758]\n",
      " [0.57377217 0.42622783]\n",
      " [0.56846336 0.43153664]\n",
      " [0.20857577 0.79142423]\n",
      " [0.20502061 0.79497939]\n",
      " [0.55244704 0.44755296]\n",
      " [0.19804575 0.80195425]]\n",
      "[ 2 21]\n",
      "[[3.80306197e-01 6.19693803e-01]\n",
      " [7.09028062e-01 2.90971938e-01]\n",
      " [8.58026375e-05 9.99914197e-01]\n",
      " [4.04176419e-01 5.95823581e-01]]\n",
      "y_probaWordsQuotes : \n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_true : \n",
      "[0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "accuracy_score : 0.8\n",
      "E2= nb  Reponses 'OUI' Détectes/Nb phrases ayant une Entité Nommée : 0.21951219512195122\n",
      "E1=nb Vraies Bonnes reponses / nb Phrases Totales : 0.8\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"training_linear_models\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "#Only WORDS\n",
    "import pandas as pd\n",
    "X= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",usecols = [\"nb Mots\"],nrows=200)\n",
    "X=np.asarray(X, dtype=np.int).reshape(-1,1)\n",
    "Y= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",usecols = [\"Entités Nommées (Nom propres)\"],nrows=200) #until row 151, so 150 values\n",
    "Y=np.asarray(Y, dtype=np.int).reshape(-1,)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X, Y)\n",
    "print(\"log_reg.score :  \"+str(log_reg.score(X,Y)))\n",
    "\n",
    "#Test\n",
    "from random import choices\n",
    "X_new = choices(range(20, 80),k=250000)\n",
    "X_new=np.asarray(X_new, dtype=np.int).reshape(-1,1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "print(y_proba)\n",
    "print(decision_boundary)\n",
    "print(log_reg.predict_proba([[37],[10],[300]]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#WORDS + QUOTES\n",
    "import pandas as pd\n",
    "X= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",usecols = [\"nb Mots\",\"nb Quotes\"],nrows=150)\n",
    "X=np.asarray(X, dtype=np.int).reshape(-1,2)\n",
    "Y= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",usecols = [\"Entités Nommées (Nom propres)\"],nrows=150) #until row 151, so 150 values\n",
    "Y=np.asarray(Y, dtype=np.int).reshape(-1,)\n",
    "print(X.shape)\n",
    "print(Y.shape) \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X, Y)\n",
    "print(\"log_reg.score(X,Y) :  \"+str(log_reg.score(X,Y)))\n",
    "\n",
    "from random import choices\n",
    "X_newQ=choices([0,1,2],k=60)\n",
    "X_newQ=np.asarray(X_newQ, dtype=np.int).reshape(-1,1)\n",
    "\n",
    "X_newW=np.arange(20, 80)\n",
    "X_newW=np.asarray(X_newW, dtype=np.int).reshape(-1,1)  #(60,1)\n",
    "\n",
    "X_new=np.array(list(zip(X_newQ, X_newW))).reshape(-1,2)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "print(y_proba)\n",
    "print(decision_boundary)\n",
    "print(log_reg.predict_proba([[2,37],[1,10],[6,300],[1,69]]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test modele Words+Quotes sur les 200 phrases :\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Mes 200 Phrases\n",
    "X_phrasesWordsQuotes= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",header=0,usecols = [\"nb Mots\",\"nb Quotes\"],nrows=200)\n",
    "X_phrasesWordsQuotes=np.asarray(X_phrasesWordsQuotes, dtype=np.int).reshape(-1,2)\n",
    "\n",
    "#On teste la proba (0 ou 1) sur nos 200 phrases\n",
    "y_probaWordsQuotes = log_reg.predict(X_phrasesWordsQuotes)  #log_reg.predict_proba pour avoir la proba de chacun\n",
    "print(\"y_probaWordsQuotes : \")\n",
    "print(y_probaWordsQuotes)\n",
    "\n",
    "#y_true est le tableau avec les vraies reponses d'entites nommes\n",
    "y_true=pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",header=0,usecols = [\"Entités Nommées (Nom propres)\"],nrows=200)\n",
    "y_true=np.asarray(y_true, dtype=np.int).reshape(-1,)\n",
    "print(\"y_true : \")\n",
    "print(y_true)\n",
    "\n",
    "\n",
    "count_a,count_b=0,0\n",
    "for i in range(len(y_true)):\n",
    "    if(y_true[i]==1):\n",
    "        count_a=count_a+1\n",
    "    if(y_probaWordsQuotes[i]==1):\n",
    "        count_b=count_b+1\n",
    "print(\"accuracy_score : \"+str(accuracy_score(y_true,y_probaWordsQuotes)))  # Score est élevé grace aux nombreux 0 ....\n",
    "\n",
    "E2=count_b/count_a\n",
    "print(\"E2= nb  Reponses 'OUI' Détectes/Nb phrases ayant une Entité Nommée : \"+str(E2))  #Score très faible pour les 1 donc ..\n",
    "\n",
    "# accuracy_score compte le nb de reponses identiques \n",
    "E1= accuracy_score(y_true,y_probaWordsQuotes,normalize=False) /200  #160/200=0.8\n",
    "print(\"E1=nb Vraies Bonnes reponses / nb Phrases Totales : \" + str(E1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",usecols = [\"nb Mots\"],nrows=200)\n",
    "X=np.asarray(X, dtype=np.int).reshape(-1,1)\n",
    "Y= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",usecols = [\"Entités Nommées (Nom propres)\"],nrows=200) #until row 151, so 150 values\n",
    "Y=np.asarray(Y, dtype=np.int).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X, Y)\n",
    "log_reg.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66801809 0.33198191]\n",
      " [0.46996296 0.53003704]\n",
      " [0.64390184 0.35609816]\n",
      " ...\n",
      " [0.36635809 0.63364191]\n",
      " [0.81504502 0.18495498]\n",
      " [0.7486044  0.2513956 ]]\n",
      "[67]\n",
      "[[7.20844867e-01 2.79155133e-01]\n",
      " [8.71098965e-01 1.28901035e-01]\n",
      " [2.19823471e-04 9.99780177e-01]]\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "X_new = choices(range(20, 80),k=250000)\n",
    "X_new=np.asarray(X_new, dtype=np.int).reshape(-1,1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "print(y_proba)\n",
    "print(decision_boundary)\n",
    "print(log_reg.predict_proba([[37],[10],[300]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "#WORDS + QUOTES\n",
    "import pandas as pd\n",
    "X= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",usecols = [\"nb Mots\",\"nb Quotes\"],nrows=150)\n",
    "X=np.asarray(X, dtype=np.int).reshape(-1,2)\n",
    "Y= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",usecols = [\"Entités Nommées (Nom propres)\"],nrows=150) #until row 151, so 150 values\n",
    "Y=np.asarray(Y, dtype=np.int).reshape(-1,)\n",
    "print(X.shape)\n",
    "print(Y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7533333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X, Y)\n",
    "log_reg.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81269997 0.18730003]\n",
      " [0.80937841 0.19062159]\n",
      " [0.45930523 0.54069477]\n",
      " [0.80260065 0.19739935]\n",
      " [0.79914425 0.20085575]\n",
      " [0.63773791 0.36226209]\n",
      " [0.79209608 0.20790392]\n",
      " [0.62766477 0.37233523]\n",
      " [0.42722468 0.57277532]\n",
      " [0.78118492 0.21881508]\n",
      " [0.41665231 0.58334769]\n",
      " [0.60719004 0.39280996]\n",
      " [0.40615604 0.59384396]\n",
      " [0.76600505 0.23399495]\n",
      " [0.76209781 0.23790219]\n",
      " [0.75814593 0.24185407]\n",
      " [0.58106486 0.41893514]\n",
      " [0.75010896 0.24989104]\n",
      " [0.7460243  0.2539757 ]\n",
      " [0.56515847 0.43484153]\n",
      " [0.55982469 0.44017531]\n",
      " [0.73350869 0.26649131]\n",
      " [0.54911678 0.45088322]\n",
      " [0.72495004 0.27504996]\n",
      " [0.72060731 0.27939269]\n",
      " [0.34037127 0.65962873]\n",
      " [0.33552204 0.66447796]\n",
      " [0.33070725 0.66929275]\n",
      " [0.70282367 0.29717633]\n",
      " [0.51134438 0.48865562]\n",
      " [0.31647699 0.68352301]\n",
      " [0.68906647 0.31093353]\n",
      " [0.68440383 0.31559617]\n",
      " [0.30258223 0.69741777]\n",
      " [0.48425912 0.51574088]\n",
      " [0.67019406 0.32980594]\n",
      " [0.66538584 0.33461416]\n",
      " [0.4680421  0.5319579 ]\n",
      " [0.65566639 0.34433361]\n",
      " [0.45726603 0.54273397]\n",
      " [0.45189232 0.54810768]\n",
      " [0.4465298  0.5534702 ]\n",
      " [0.26306533 0.73693467]\n",
      " [0.43584322 0.56415678]\n",
      " [0.43052155 0.56947845]\n",
      " [0.25065564 0.74934436]\n",
      " [0.61553753 0.38446247]\n",
      " [0.24260203 0.75739797]\n",
      " [0.23864178 0.76135822]\n",
      " [0.60003909 0.39996091]\n",
      " [0.39896797 0.60103203]\n",
      " [0.39378229 0.60621771]\n",
      " [0.38862042 0.61137958]\n",
      " [0.38348342 0.61651658]\n",
      " [0.21582168 0.78417832]\n",
      " [0.37328804 0.62671196]\n",
      " [0.36823164 0.63176836]\n",
      " [0.20502061 0.79497939]\n",
      " [0.35820616 0.64179384]\n",
      " [0.54708229 0.45291771]]\n",
      "[ 2 22]\n",
      "[[3.80306197e-01 6.19693803e-01]\n",
      " [7.09028062e-01 2.90971938e-01]\n",
      " [8.58026375e-05 9.99914197e-01]\n",
      " [4.04176419e-01 5.95823581e-01]]\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "X_newQ=choices([0,1,2],k=60)\n",
    "X_newQ=np.asarray(X_newQ, dtype=np.int).reshape(-1,1)\n",
    "\n",
    "X_newW=np.arange(20, 80)\n",
    "X_newW=np.asarray(X_newW, dtype=np.int).reshape(-1,1)  #(60,1)\n",
    "\n",
    "X_new=np.array(list(zip(X_newQ, X_newW))).reshape(-1,2)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "print(y_proba)\n",
    "print(decision_boundary)\n",
    "print(log_reg.predict_proba([[2,37],[1,10],[6,300],[1,69]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_probaWordsQuotes : \n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_true : \n",
      "[0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "accuracy_score : 0.8\n",
      "E2= nb  Reponses 'OUI' Détectes/Nb phrases ayant une Entité Nommée : 0.21951219512195122\n",
      "E1=nb Vraies Bonnes reponses / nb Phrases Totales : 0.8\n"
     ]
    }
   ],
   "source": [
    "#test modele Words+Quotes sur les 200 phrases :\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Mes 200 Phrases\n",
    "X_phrasesWordsQuotes= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",header=0,usecols = [\"nb Mots\",\"nb Quotes\"],nrows=200)\n",
    "X_phrasesWordsQuotes=np.asarray(X_phrasesWordsQuotes, dtype=np.int).reshape(-1,2)\n",
    "\n",
    "#On teste la proba (0 ou 1) sur nos 200 phrases\n",
    "y_probaWordsQuotes = log_reg.predict(X_phrasesWordsQuotes)  #log_reg.predict_proba pour avoir la proba de chacun\n",
    "print(\"y_probaWordsQuotes : \")\n",
    "print(y_probaWordsQuotes)\n",
    "\n",
    "#y_true est le tableau avec les vraies reponses d'entites nommes\n",
    "y_true=pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",header=0,usecols = [\"Entités Nommées (Nom propres)\"],nrows=200)\n",
    "y_true=np.asarray(y_true, dtype=np.int).reshape(-1,)\n",
    "print(\"y_true : \")\n",
    "print(y_true)\n",
    "\n",
    "\n",
    "count_a,count_b=0,0\n",
    "for i in range(len(y_true)):\n",
    "    if(y_true[i]==1):\n",
    "        count_a=count_a+1\n",
    "    if(y_probaWordsQuotes[i]==1):\n",
    "        count_b=count_b+1\n",
    "print(\"accuracy_score : \"+str(accuracy_score(y_true,y_probaWordsQuotes)))  # Score est élevé grace aux nombreux 0 ....\n",
    "\n",
    "E2=count_b/count_a\n",
    "print(\"E2= nb  Reponses 'OUI' Détectes/Nb phrases ayant une Entité Nommée : \"+str(E2))  #Score très faible pour les 1 donc ..\n",
    "\n",
    "# accuracy_score compte le nb de reponses identiques \n",
    "E1= accuracy_score(y_true,y_probaWordsQuotes,normalize=False) /200  #160/200=0.8\n",
    "print(\"E1=nb Vraies Bonnes reponses / nb Phrases Totales : \" + str(E1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features per sample; expecting 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a1882a6bf3d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#On teste la proba (0 ou 1) sur nos 200 phrases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my_probaWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_phrasesWords\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#log_reg.predict_proba pour avoir la proba de chacun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_probaWords : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_probaWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1409\u001b[0m                                                 self.solver == 'liblinear')))\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \"\"\"\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features per sample; expecting 2"
     ]
    }
   ],
   "source": [
    "#Test sur Uniquement Words\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Mes 200 Phrases\n",
    "X_phrasesWords= pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",header=0,usecols = [\"nb Mots\"],nrows=200)\n",
    "X_phrasesWords=np.asarray(X_phrasesWords, dtype=np.int).reshape(-1,1)\n",
    "\n",
    "#On teste la proba (0 ou 1) sur nos 200 phrases\n",
    "y_probaWords = log_reg.predict_proba(X_phrasesWords)  #log_reg.predict_proba pour avoir la proba de chacun\n",
    "print(\"y_probaWords : \")\n",
    "print(y_probaWords)\n",
    "\n",
    "#y_true est le tableau avec les vraies reponses d'entites nommes\n",
    "y_true=pd.read_csv(\"tableur_606EN.csv\", encoding = \"ISO-8859-1\",sep=\";\",header=0,usecols = [\"Entités Nommées (Nom propres)\"],nrows=200)\n",
    "y_true=np.asarray(y_true, dtype=np.int).reshape(-1,)\n",
    "print(\"y_true : \")\n",
    "print(y_true)\n",
    "\n",
    "\n",
    "count_a,count_b=0,0\n",
    "for i in range(len(y_true)):\n",
    "    if(y_true[i]==1):\n",
    "        count_a=count_a+1\n",
    "    if(y_probaWordsQuotes[i]==1):\n",
    "        count_b=count_b+1\n",
    "print(\"accuracy_score : \"+str(accuracy_score(y_true,y_probaWordsQuotes)))  # Score est élevé grace aux nombreux 0 ....\n",
    "\n",
    "E2=count_b/count_a\n",
    "print(\"E2= nb  Reponses 'OUI' Détectes/Nb phrases ayant une Entité Nommée : \"+str(E2))  #Score très faible pour les 1 donc ..\n",
    "\n",
    "# accuracy_score compte le nb de reponses identiques \n",
    "E1= accuracy_score(y_true,y_probaWordsQuotes,normalize=False) /200  #160/200=0.8\n",
    "print(\"E1=nb Vraies Bonnes reponses / nb Phrases Totales : \" + str(E1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
